{
  "name": "Parallelizing Neural Network Training",
  "tagline": "Xiaotian Cao (xcao1)",
  "body": "#Project Checkpoint\r\n### Checkpoint Report\r\n\r\nAs of Apr 19th, I have implemented a neural network that is able to take in data and make predictions. Currently it does not have anything parallel at the moment. And it is not able to constantly pulling new data and make predictions. Overall, I think I am still on schedule or maybe just a little bit behind. Nonetheless, after more researching and discuss with people, I decided to scale down my project goal a little bit. Currently, I want to focus on single-node training using OpenMP and maybe SIMD. I decided to put the idea of multi-node training on hold because it seems to involve a lot of extra work. I am not sure If I will be able to implement a multi-node training framework on time.\r\n\r\nOn the day of presentation, I intend to have graphs that display the speedup obtain by parallelized training. In addition, I want to present graphs that shows the predicted stock price vs actual stock price. If possible, I hope demo a real time prediction vs actual chart.\r\n\r\nLastly, here is a more detailed schedule for the rest of the project:\r\n\r\n- **April 22**: Use open mp to parallelize the training part and able to run on latedays.\r\n- **April 27**: Implement a program that constantly collects real time stock data and feed to the neural network.\r\n- **May 4**: A program that constantly pulls real-time data and emit stock prediction.\r\n- **May 6**: Final writeup\r\n\r\n#Project Proposal\r\n### Summary\r\nI am going to implement an application that predicts stock price. It would involve using neural network and I will parallelize the training process using multi-core cpu platforms/clusters. \r\n\r\n### Background\r\nThe training process for neural network has good potential for speedup. A neural network is usually composed of number of neurons separated into multiple levels. Matrix multiplication is usually involved in calculating weights for each neuron. In addition, when using backward propagation algorithm, at each layer, neurons are usually independent from each other. Therefore, we could compute weights for these independent neurons in parallel. Therefore, with large amount of data, we should see a significant speedup after we parallelized the training process.  \r\n\r\n### The Challenge\r\nThere are a few challenges when trying to parallelize the training process. \r\n- When using backward propagation, we need to make sure each cpu completes jobs layer by layer. \r\n- Since we can get real time quotes for stock price, if we want to exploit this fact, we need to make sure each node has same up-to-date copy of data.\r\n\r\n### Resources\r\nFor this project, I will use Lateday clusters to carry out the training process. Yahoo API will help me to obtain real-time stock quotes. In terms of code, I will start the project from scratch. Lastly, there are a few paper that talks about either stock prediction using Neural Networks or parallelizing Neural Networks training.\r\n\r\n  1. Abhishek, K., A. Khairwa, T. Pratap, and S. Prakash. \"A Stock Market Prediction Model Using Artificial Neural Network.\" 2012 Third International Conference on Computing, Communication and Networking Technologies (ICCCNT'12) (2012): n. pag. Web.\r\n\r\n  2. Dahl, George, Alan McAvinney, and Tia Newhall. \"Parallelizing neural network training for cluster systems.\" Proceedings of the IASTED International Conference on Parallel and Distributed Computing and Networks. ACTA Press, 2008.\r\n\r\n### Goals and Deliverables\r\n- **Plan to achieve:** \r\n⋅⋅1. A program that emits stock price prediction about every second. It also displays actual stock price on the side.\r\n⋅⋅2. speed up that is close to linear in terms of number of nodes in the training process. I believe this can be done since the workload for calculating the weights for each neuron should be similar. \r\n⋅⋅3. fairly accurate prediction of stock price for the next minute.\r\n⋅⋅4. a graph that shows prediction vs actual data\r\n- **Hope to achieve:** \r\n⋅⋅1. High accuracy prediction.\r\n⋅⋅2. Linear speed up or more than linear speed up.\r\n\r\n###Platform Choice\r\n\r\nI will use Latedays machine to help me speed up the training process. And I will use C++ as the language because I am planning to experiment SIMD and OpenMP. Latedays are powerful cluster that allows me to split tasks across nodes. SIMD and OpenMp would be helpful when performing matrix multiplcation. \r\n###Schedule\r\n\r\n- **April 15**: A working Neural Network implementation that is able to emit stock prediction.\r\n- **April 22**: Parallelize matrix multiplication part.\r\n- **April 29**: Parallelize training process in terms of layers.\r\n- **May 6**: A program that constantly pulls real-time data and emit stock prediction.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}